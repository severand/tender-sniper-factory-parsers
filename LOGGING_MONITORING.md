# üìä Factory Parsers - –°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

## üéØ –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–û–±–∑–æ—Ä](#–æ–±–∑–æ—Ä)
2. [–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ (JSON)](#—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ-–ª–æ–≥–∏-json)
3. [–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä –ª–æ–≥–æ–≤](#—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π-—Å–±–æ—Ä-–ª–æ–≥–æ–≤)
4. [–ú–µ—Ç—Ä–∏–∫–∏ Prometheus](#–º–µ—Ç—Ä–∏–∫–∏-prometheus)
5. [–ê–ª–µ—Ä—Ç—ã](#–∞–ª–µ—Ä—Ç—ã)
6. [Grafana –¥–∞—à–±–æ—Ä–¥—ã](#grafana-–¥–∞—à–±–æ—Ä–¥—ã)
7. [–ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è](#–∏–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è)
8. [–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤](#–ø—Ä–∏–º–µ—Ä—ã-–∑–∞–ø—Ä–æ—Å–æ–≤)

---

## üéØ –û–±–∑–æ—Ä

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

```
factory_parsers services (13 modules)
        ‚Üì
    structlog (JSON formatter)
        ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Centralized Log Collector   ‚îÇ
    ‚îÇ  (ELK Stack –∏–ª–∏ EFK –∏–ª–∏ Loki) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üô              ‚Üì              ‚Üñ
   Elasticsearch   PostgreSQL    Prometheus
        ‚Üì              ‚Üì              ‚Üì
   Kibana UI    Grafana Logs    Grafana Metrics
```

### –¢—Ä—ë—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞

1. **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ (JSON)** ‚Üí –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã –ø–∏—à—É—Ç JSON
2. **–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä** ‚Üí ELK/EFK/Loki —Å–æ–±–∏—Ä–∞–µ—Ç –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ
3. **–ú–µ—Ç—Ä–∏–∫–∏ & –ê–ª–µ—Ä—Ç—ã** ‚Üí Prometheus + Grafana –¥–ª—è KPI –∏ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤

---

## üìù –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ (JSON)

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è

–í—Å–µ –ª–æ–≥–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç:

```json
{
  "timestamp": "2025-12-16T20:30:45.123Z",
  "service": "web_scraper_service",
  "worker": "scrapy-worker-1",
  "environment": "production",
  "version": "1.0.0",
  
  "platform_id": "e-tender-kz",
  "tender_id": "uuid-123",
  "file_id": "uuid-456",
  "task_id": "celery-task-789",
  "request_id": "req-999",
  
  "event_type": "success",
  "message": "Tender parsed successfully",
  "level": "info",
  
  "http_status": 200,
  "proxy_id": "proxy-rotation-12",
  "captcha_used": false,
  "captcha_type": null,
  "duration_ms": 1234,
  
  "retry_count": 0,
  "error_code": null,
  "error_message": null,
  "stack_trace": null,
  
  "metadata": {
    "url": "https://example.com/tender/123",
    "page_number": 1,
    "selector_used": "div.tender-item",
    "items_count": 50,
    "js_rendered": true,
    "cloudflare_detected": false,
    "rate_limited": false
  }
}
```

### –¢–∏–ø—ã —Å–æ–±—ã—Ç–∏–π (event_type)

| –¢–∏–ø | –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è | –ü—Ä–∏–º–µ—Ä |
|-----|---|---|
| **start** | –ù–∞—á–∞–ª–æ –æ–ø–µ—Ä–∞—Ü–∏–∏ | –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–µ–Ω–¥–µ—Ä–∞ |
| **success** | –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ | –¢–µ–Ω–¥–µ—Ä —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω, –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã |
| **retry** | –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ | 3-—è –ø–æ–ø—ã—Ç–∫–∞ –ø–æ—Å–ª–µ timeout |
| **error** | –û—à–∏–±–∫–∞ (–ª–æ–≥–∏—Ä—É–µ—Ç—Å—è, –æ–ø–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å—Å—è) | HTTP 429, –∫–∞–ø—á–∞ –Ω–µ —Ä–µ—à–µ–Ω–∞ |
| **circuit_breaker** | –°—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ circuit breaker | –ú–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –æ—Ç –ø–ª–æ—â–∞–¥–∫–∏, –æ—Ç–∫–ª—é—á–∞–µ–º –Ω–∞ N —Å–µ–∫ |
| **warning** | –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ | Rate limit —Å–∫–æ—Ä–æ, –Ω—É–∂–Ω–æ –∑–∞–º–µ–¥–ª–∏—Ç—å—Å—è |
| **metrics** | –ú–µ—Ç—Ä–∏–∫–∞ (–Ω–µ –æ—à–∏–±–∫–∞, –Ω–µ —Å–æ–±—ã—Ç–∏–µ, –ø—Ä–æ—Å—Ç–æ –º–µ—Ä–∞) | –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 1000 —Ç–µ–Ω–¥–µ—Ä–æ–≤, —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è 2.5s |

### –ü—Ä–∏–º–µ—Ä—ã —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–æ–≥–æ–≤

#### ‚úÖ –£—Å–ø–µ—à–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥

```json
{
  "timestamp": "2025-12-16T20:30:45.123Z",
  "service": "web_scraper_service",
  "worker": "scrapy-worker-5",
  "platform_id": "e-tender-kz",
  "tender_id": "ETK-2025-001234",
  "task_id": "task-abc123",
  "event_type": "success",
  "message": "Tender parsed and saved",
  "level": "info",
  "http_status": 200,
  "proxy_id": "proxy-rotation-3",
  "captcha_used": false,
  "duration_ms": 2150,
  "metadata": {
    "url": "https://www.etender.kz/tender/2025-001234",
    "items_found": 1,
    "js_rendered": true,
    "cloudflare_detected": false
  }
}
```

#### ‚ö†Ô∏è –ö–∞–ø—á–∞ —Å—Ä–∞–±–∞—Ç–∏–ª–∞, –Ω–æ —Ä–µ—à–µ–Ω–∞

```json
{
  "timestamp": "2025-12-16T20:31:12.456Z",
  "service": "web_scraper_service",
  "worker": "scrapy-worker-7",
  "platform_id": "zakupki-gov-ru",
  "tender_id": "ZAKUPKI-2025-005678",
  "task_id": "task-def456",
  "event_type": "success",
  "message": "Tender fetched after captcha",
  "level": "warning",
  "http_status": 403,
  "proxy_id": "proxy-rotation-8",
  "captcha_used": true,
  "captcha_type": "recaptcha_v3",
  "duration_ms": 8500,
  "retry_count": 1,
  "metadata": {
    "url": "https://zakupki.gov.ru/223/purchase/562345",
    "captcha_solve_time_ms": 5000,
    "captcha_attempts": 1,
    "captcha_cost_usd": 0.003
  }
}
```

#### ‚ùå –û—à–∏–±–∫–∞ (429 - Rate Limited)

```json
{
  "timestamp": "2025-12-16T20:32:05.789Z",
  "service": "web_scraper_service",
  "worker": "scrapy-worker-2",
  "platform_id": "e-tender-kz",
  "tender_id": "ETK-2025-009999",
  "task_id": "task-ghi789",
  "event_type": "retry",
  "message": "Rate limited, retrying in 60s",
  "level": "warning",
  "http_status": 429,
  "proxy_id": "proxy-rotation-5",
  "captcha_used": false,
  "duration_ms": 350,
  "retry_count": 2,
  "error_code": "HTTP_429",
  "error_message": "Too Many Requests",
  "metadata": {
    "url": "https://www.etender.kz/tender/2025-009999",
    "retry_after_seconds": 60,
    "requests_per_minute": 45,
    "rate_limit_per_minute": 30
  }
}
```

#### üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (circuit breaker)

```json
{
  "timestamp": "2025-12-16T20:33:02.012Z",
  "service": "web_scraper_service",
  "worker": "scheduler",
  "platform_id": "unknown-platform",
  "task_id": "task-jkl012",
  "event_type": "circuit_breaker",
  "message": "Circuit breaker triggered for platform",
  "level": "error",
  "http_status": null,
  "error_code": "CIRCUIT_BREAKER_OPEN",
  "error_message": "Platform returned 10 consecutive errors (5xx) in 5 minutes",
  "metadata": {
    "platform": "unknown-platform",
    "consecutive_errors": 10,
    "error_types": ["503", "503", "500", "503", "502", "503", "500", "503", "503", "503"],
    "circuit_open_duration_seconds": 300,
    "notify_admin": true
  }
}
```

#### üìä –ú–µ—Ç—Ä–∏–∫–∞ (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ —Ä–∞–±–æ—Ç–µ)

```json
{
  "timestamp": "2025-12-16T20:35:00.000Z",
  "service": "scheduler_service",
  "event_type": "metrics",
  "message": "Hourly statistics",
  "level": "info",
  "metadata": {
    "period_minutes": 60,
    "tenders_processed": 1234,
    "tenders_success": 1180,
    "tenders_failed": 54,
    "success_rate_percent": 95.6,
    "avg_processing_time_ms": 2340,
    "captchas_solved": 78,
    "captcha_success_rate_percent": 94.2,
    "proxies_used": 12,
    "platforms_active": 4,
    "platform_stats": {
      "e-tender-kz": {"count": 580, "errors": 15, "rate_limit_hits": 8},
      "zakupki-gov-ru": {"count": 350, "errors": 22, "rate_limit_hits": 18},
      "planfact-kz": {"count": 200, "errors": 10, "rate_limit_hits": 3},
      "sberbank-ru": {"count": 104, "errors": 7, "rate_limit_hits": 2}
    }
  }
}
```

---

## üåê –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä –ª–æ–≥–æ–≤

### –í–∞—Ä–∏–∞–Ω—Ç 1: ELK Stack (Elasticsearch + Logstash + Kibana)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ú–æ—â–Ω—ã–π –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
- –û–≥—Ä–æ–º–Ω–æ–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ
- Enterprise-ready

**docker-compose.yml:**

```yaml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.0.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.0.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5000:5000"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.0.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch

volumes:
  elasticsearch_data:
```

**logstash.conf:**

```
input {
  tcp {
    port => 5000
    codec => json
  }
}

filter {
  if [service] {
    mutate {
      add_field => { "[@metadata][index_name]" => "%{service}-%{+YYYY.MM.dd}" }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index_name]}"
  }
}
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: EFK Stack (Elasticsearch + Fluent Bit + Kibana)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –õ–µ–≥—á–µ —á–µ–º Logstash
- –ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏
- –ë—ã—Å—Ç—Ä–µ–µ –¥–ª—è –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

**fluent-bit.conf:**

```
[SERVICE]
    Flush        5
    Daemon       Off
    Log_Level    info

[INPUT]
    Name              tail
    Path              /var/log/factory_parsers/*.json
    Parser            json
    Tag               factory_parsers.*
    Refresh_Interval  5

[FILTER]
    Name    modify
    Match   *
    Add     cluster_id my-cluster
    Add     environment production

[OUTPUT]
    Name            es
    Match           *
    Host            elasticsearch
    Port            9200
    Logstash_Format On
    Logstash_Prefix factory_parsers
    Type            _doc
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: Loki (Grafana Loki)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏, —á–µ–º Elasticsearch
- –í—Å—Ç—Ä–æ–µ–Ω–∞ –≤ Grafana
- –û—Ç–ª–∏—á–Ω—ã–π –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

**loki-config.yml:**

```yaml
auth_enabled: false

ingester:
  chunk_idle_period: 3m
  chunk_retain_period: 1m
  max_chunk_age: 1h
  chunk_encoding: gzip

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema:
        version: v11
        index:
          prefix: index_
          period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /loki/boltdb-shipper-active
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks

server:
  http_listen_port: 3100

# http_server_read_timeout: 600s
# http_server_write_timeout: 600s
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ Python (structlog)

**factory_parsers/shared/logger.py:**

```python
import json
import logging
import sys
from typing import Any, Dict, Optional
from datetime import datetime, timezone

import structlog
from pythonjsonlogger import jsonlogger


class CustomJsonFormatter(jsonlogger.JsonFormatter):
    """Custom JSON formatter with required fields."""
    
    def add_fields(
        self,
        log_record: Dict[str, Any],
        record: logging.LogRecord,
        message_dict: Dict[str, Any]
    ) -> None:
        """Add custom fields to log record."""
        super().add_fields(log_record, record, message_dict)
        
        # Add timestamp in ISO format
        log_record['timestamp'] = datetime.now(timezone.utc).isoformat()
        
        # Ensure required fields exist
        log_record.setdefault('service', 'factory_parsers')
        log_record.setdefault('worker', 'unknown')
        log_record.setdefault('environment', 'production')
        log_record.setdefault('version', '1.0.0')
        log_record.setdefault('event_type', 'log')
        log_record.setdefault('duration_ms', None)
        log_record.setdefault('retry_count', 0)


def setup_logging(service_name: str, worker_name: str = "default"):
    """Setup structured logging with JSON output."""
    
    # Configure structlog
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        cache_logger_on_first_use=True,
    )
    
    # Setup Python logging
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    
    # JSON handler to stdout
    json_handler = logging.StreamHandler(sys.stdout)
    json_handler.setLevel(logging.DEBUG)
    formatter = CustomJsonFormatter('%(service)s %(event_type)s %(message)s')
    json_handler.setFormatter(formatter)
    root_logger.addHandler(json_handler)
    
    # Get structlog logger
    logger = structlog.get_logger(service_name)
    
    # Bind context
    logger = logger.bind(
        service=service_name,
        worker=worker_name,
        environment="production"
    )
    
    return logger


# Usage in services
logger = setup_logging("web_scraper_service", "scrapy-worker-1")

# Log success
logger.info(
    "tender_parsed",
    event_type="success",
    tender_id="ETK-2025-001",
    platform_id="e-tender-kz",
    http_status=200,
    proxy_id="proxy-5",
    captcha_used=False,
    duration_ms=2150,
    metadata={
        "url": "https://example.com/tender/123",
        "items_count": 1
    }
)

# Log error with retry
logger.warning(
    "rate_limited",
    event_type="retry",
    tender_id="ETK-2025-002",
    platform_id="e-tender-kz",
    http_status=429,
    proxy_id="proxy-7",
    retry_count=2,
    duration_ms=450,
    error_code="HTTP_429",
    error_message="Too Many Requests"
)
```

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏ Prometheus

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Prometheus

**prometheus.yml:**

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'factory_parsers'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
```

### –ú–µ—Ç—Ä–∏–∫–∏ (Python –∫–æ–¥)

**factory_parsers/shared/metrics.py:**

```python
from prometheus_client import (
    Counter, Histogram, Gauge, generate_latest,
    CollectorRegistry, REGISTRY
)
import time

# Registries
registry = REGISTRY

# Counters - –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–µ —Å—á—ë—Ç—á–∏–∫–∏
tasks_total = Counter(
    'factory_parsers_tasks_total',
    'Total tasks processed',
    ['service', 'task_type', 'status'],
    registry=registry
)

tasks_retried = Counter(
    'factory_parsers_tasks_retried_total',
    'Total task retries',
    ['service', 'reason'],
    registry=registry
)

http_requests_total = Counter(
    'factory_parsers_http_requests_total',
    'Total HTTP requests',
    ['service', 'platform', 'status_code'],
    registry=registry
)

http_errors_total = Counter(
    'factory_parsers_http_errors_total',
    'Total HTTP errors by type',
    ['service', 'platform', 'error_code'],
    registry=registry
)

captchas_solved_total = Counter(
    'factory_parsers_captchas_solved_total',
    'Total captchas solved',
    ['service', 'captcha_type', 'status'],
    registry=registry
)

proxy_failures_total = Counter(
    'factory_parsers_proxy_failures_total',
    'Total proxy failures',
    ['service', 'proxy_id', 'reason'],
    registry=registry
)

# Histograms - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
task_duration_seconds = Histogram(
    'factory_parsers_task_duration_seconds',
    'Task processing duration',
    ['service', 'task_type'],
    buckets=(0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0),
    registry=registry
)

api_response_time_seconds = Histogram(
    'factory_parsers_api_response_time_seconds',
    'API response time',
    ['service', 'platform', 'endpoint'],
    buckets=(0.1, 0.5, 1.0, 2.0, 5.0, 10.0),
    registry=registry
)

file_processing_time_seconds = Histogram(
    'factory_parsers_file_processing_time_seconds',
    'File processing time (extract/AI)',
    ['service', 'file_type'],
    buckets=(0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0),
    registry=registry
)

# Gauges - —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
active_tasks = Gauge(
    'factory_parsers_active_tasks',
    'Currently active tasks',
    ['service'],
    registry=registry
)

proxy_health = Gauge(
    'factory_parsers_proxy_health',
    'Proxy health status (1=healthy, 0=unhealthy)',
    ['proxy_id'],
    registry=registry
)

crawler_queue_size = Gauge(
    'factory_parsers_crawler_queue_size',
    'Size of crawler queue',
    ['service', 'queue_name'],
    registry=registry
)

# Rate - –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫
error_rate = Gauge(
    'factory_parsers_error_rate_percent',
    'Error rate percentage',
    ['service', 'period'],
    registry=registry
)

captcha_rate_per_thousand = Gauge(
    'factory_parsers_captcha_rate_per_thousand',
    'Captchas per 1000 requests',
    ['service', 'platform'],
    registry=registry
)

# Usage examples

def track_task(service: str, task_type: str, success: bool, duration_ms: float):
    """Track task execution."""
    status = 'success' if success else 'error'
    tasks_total.labels(service=service, task_type=task_type, status=status).inc()
    task_duration_seconds.labels(service=service, task_type=task_type).observe(duration_ms / 1000)

def track_http_request(service: str, platform: str, status_code: int, duration_ms: float):
    """Track HTTP request."""
    http_requests_total.labels(service=service, platform=platform, status_code=status_code).inc()
    api_response_time_seconds.labels(service=service, platform=platform, endpoint="/").observe(duration_ms / 1000)
    
    if status_code >= 400:
        if status_code == 429:
            http_errors_total.labels(service=service, platform=platform, error_code="RATE_LIMITED").inc()
        elif status_code == 403:
            http_errors_total.labels(service=service, platform=platform, error_code="FORBIDDEN").inc()
        elif status_code >= 500:
            http_errors_total.labels(service=service, platform=platform, error_code="SERVER_ERROR").inc()

def track_captcha(service: str, captcha_type: str, solved: bool):
    """Track captcha attempt."""
    status = 'solved' if solved else 'failed'
    captchas_solved_total.labels(service=service, captcha_type=captcha_type, status=status).inc()

def set_active_tasks(service: str, count: int):
    """Set number of active tasks."""
    active_tasks.labels(service=service).set(count)
```

### –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º

| –ú–µ—Ç—Ä–∏–∫–∞ | Type | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|---------|------|----------|
| `tasks_total` | Counter | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á (—É—Å–ø–µ—à–Ω–æ/–æ—à–∏–±–∫–∞/–æ—Ç–∫–ª–æ–Ω–µ–Ω–æ) |
| `tasks_retried_total` | Counter | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—Ç—Ä–∞–µ–≤ |
| `http_requests_total` | Counter | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ HTTP –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ status |
| `http_errors_total` | Counter | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ (429, 403, 5xx) |
| `captchas_solved_total` | Counter | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–∞–ø—á |
| `proxy_failures_total` | Counter | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–±–æ–µ–≤ –ø—Ä–æ–∫—Å–∏ |
| `task_duration_seconds` | Histogram | –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–¥–∞—á |
| `api_response_time_seconds` | Histogram | –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç API –ø–ª–æ—â–∞–¥–æ–∫ |
| `file_processing_time_seconds` | Histogram | –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤ |
| `active_tasks` | Gauge | –¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á |
| `proxy_health` | Gauge | –ó–¥–æ—Ä–æ–≤—å–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–∫—Å–∏ (1/0) |
| `crawler_queue_size` | Gauge | –†–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏ –ø–∞—Ä—Å–µ—Ä–∞ |
| `error_rate_percent` | Gauge | –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ |
| `captcha_rate_per_thousand` | Gauge | –ö–∞–ø—á –Ω–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤ |

---

## üö® –ê–ª–µ—Ä—Ç—ã

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤ Prometheus

**alert-rules.yml:**

```yaml
groups:
  - name: factory_parsers_alerts
    interval: 30s
    rules:
      # –†–µ–∑–∫–∏–π —Ä–æ—Å—Ç 429/403 –æ—à–∏–±–æ–∫
      - alert: HighRateLimitErrors
        expr: |
          rate(factory_parsers_http_errors_total{
            error_code=~"RATE_LIMITED|FORBIDDEN"
          }[5m]) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High rate limiting on {{ $labels.platform }}"
          description: "Platform {{ $labels.platform }} returning 429/403 at {{ $value }} errors/sec"

      # –ü–∞–¥–µ–Ω–∏–µ throughput
      - alert: LowThroughput
        expr: |
          rate(factory_parsers_tasks_total{
            status="success"
          }[5m]) < 1.0
        for: 10m
        labels:
          severity: critical
        annotations:
          summary: "Low throughput on {{ $labels.service }}"
          description: "Task success rate fell below 1/sec"

      # –†–æ—Å—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
      - alert: HighFileProcessingTime
        expr: |
          histogram_quantile(0.95,
            rate(factory_parsers_file_processing_time_seconds_bucket[5m])
          ) > 60
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High file processing time"
          description: "95th percentile of file processing time is {{ $value }}s"

      # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ (>10%)
      - alert: HighErrorRate
        expr: |
          (
            rate(factory_parsers_tasks_total{
              status="error"
            }[5m])
            /
            rate(factory_parsers_tasks_total[5m])
          ) * 100 > 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∫–∞–ø—á (>100 –Ω–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤)
      - alert: ExcessiveCaptchaRate
        expr: |
          factory_parsers_captcha_rate_per_thousand > 100
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Excessive captcha rate on {{ $labels.platform }}"
          description: "Captcha rate is {{ $value }} per 1000 requests"

      # –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –≤–µ—Ä–Ω—É–ª–∞ 10+ –æ—à–∏–±–æ–∫ 5xx –ø–æ–¥—Ä—è–¥
      - alert: PlatformServerErrors
        expr: |
          increase(factory_parsers_http_errors_total{
            error_code="SERVER_ERROR"
          }[5m]) > 10
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "Platform {{ $labels.platform }} returning many 5xx errors"
          description: "{{ $value }} server errors in last 5 minutes"

      # –û—Ç–∫–∞–∑ –ø—Ä–æ–∫—Å–∏
      - alert: ProxyDown
        expr: |
          factory_parsers_proxy_health == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Proxy {{ $labels.proxy_id }} is down"
          description: "Proxy health is 0 for more than 2 minutes"

      # –ü–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏
      - alert: QueueBacklog
        expr: |
          factory_parsers_crawler_queue_size > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Crawler queue backlog"
          description: "Queue size is {{ $value }} items"

      # –†–µ—Ç—Ä–∞–∏ –≤„É´„Éº„Éó–µ
      - alert: HighRetryRate
        expr: |
          rate(factory_parsers_tasks_retried_total[5m]) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High retry rate on {{ $labels.service }}"
          description: "Retry rate is {{ $value }} per second"
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–ª–µ—Ä—Ç–æ–≤

**–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Slack:**

```yaml
alert_manager_config:
  route:
    group_by: ['alertname', 'cluster']
    group_wait: 10s
    group_interval: 10s
    repeat_interval: 1h
    receiver: 'slack'
  receivers:
    - name: 'slack'
      slack_configs:
        - api_url: '${SLACK_WEBHOOK_URL}'
          channel: '#factory-parsers-alerts'
          title: 'Alert: {{ .GroupLabels.alertname }}'
          text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
```

---

## üìà Grafana –î–∞—à–±–æ—Ä–¥—ã

### –î–∞—à–±–æ—Ä–¥ 1: System Overview (–æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)

```json
{
  "dashboard": {
    "title": "Factory Parsers - System Overview",
    "panels": [
      {
        "title": "Tasks Per Second",
        "targets": [
          {
            "expr": "rate(factory_parsers_tasks_total[1m])"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Error Rate %",
        "targets": [
          {
            "expr": "(rate(factory_parsers_tasks_total{status='error'}[5m]) / rate(factory_parsers_tasks_total[5m])) * 100"
          }
        ],
        "type": "gauge",
        "thresholds": "5,10"
      },
      {
        "title": "HTTP Status Codes",
        "targets": [
          {
            "expr": "rate(factory_parsers_http_requests_total[1m])",
            "legendFormat": "{{ status_code }}"
          }
        ],
        "type": "piechart"
      },
      {
        "title": "Captcha Rate per 1000 Requests",
        "targets": [
          {
            "expr": "factory_parsers_captcha_rate_per_thousand",
            "legendFormat": "{{ platform }}"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

### –î–∞—à–±–æ—Ä–¥ 2: Platform Performance (–ø–æ –ø–ª–æ—â–∞–¥–∫–∞–º)

```json
{
  "dashboard": {
    "title": "Factory Parsers - Platform Performance",
    "templating": {
      "list": [
        {
          "name": "platform",
          "type": "query",
          "datasource": "Prometheus",
          "query": "label_values(factory_parsers_http_requests_total, platform)",
          "multi": true
        }
      ]
    },
    "panels": [
      {
        "title": "{{ platform }} - Requests/sec",
        "targets": [
          {
            "expr": "rate(factory_parsers_http_requests_total{platform=\"$platform\"}[1m])"
          }
        ]
      },
      {
        "title": "{{ platform }} - Error Types",
        "targets": [
          {
            "expr": "rate(factory_parsers_http_errors_total{platform=\"$platform\"}[5m])",
            "legendFormat": "{{ error_code }}"
          }
        ]
      },
      {
        "title": "{{ platform }} - Response Time (p95)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(factory_parsers_api_response_time_seconds_bucket{platform=\"$platform\"}[5m]))"
          }
        ]
      },
      {
        "title": "{{ platform }} - Captcha Usage",
        "targets": [
          {
            "expr": "rate(factory_parsers_captchas_solved_total{platform=\"$platform\"}[5m])",
            "legendFormat": "{{ captcha_type }}"
          }
        ]
      }
    ]
  }
}
```

### –î–∞—à–±–æ—Ä–¥ 3: Proxy & Network Health (–ø—Ä–æ–∫—Å–∏)

```json
{
  "dashboard": {
    "title": "Factory Parsers - Proxy & Network",
    "panels": [
      {
        "title": "Proxy Health Status",
        "targets": [
          {
            "expr": "factory_parsers_proxy_health",
            "legendFormat": "{{ proxy_id }}"
          }
        ],
        "type": "table"
      },
      {
        "title": "Proxy Failure Rate",
        "targets": [
          {
            "expr": "rate(factory_parsers_proxy_failures_total[5m])",
            "legendFormat": "{{ proxy_id }} - {{ reason }}"
          }
        ]
      },
      {
        "title": "Rate Limit Hits by Proxy",
        "targets": [
          {
            "expr": "rate(factory_parsers_http_errors_total{error_code='RATE_LIMITED'}[5m])",
            "legendFormat": "{{ platform }}"
          }
        ]
      }
    ]
  }
}
```

### –î–∞—à–±–æ—Ä–¥ 4: Logs (Kibana/Loki)

**Kibana Queries:**

```
# –í—Å–µ –æ—à–∏–±–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
service.keyword:"web_scraper_service" AND event_type:"error" AND timestamp:[now-1h TO now]

# –ö–∞–ø—á–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ä–µ—à–µ–Ω—ã
service.keyword:"web_scraper_service" AND captcha_used:true AND event_type:"error"

# 429 –æ—à–∏–±–∫–∏ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º
http_status:429 | stats count() by platform_id

# –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
| stats avg(duration_ms) by task_type

# –ü—Ä–æ–∫—Å–∏, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—â–µ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è
http_status:"403" | stats count() by proxy_id | sort - count
```

---

## üíª –ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è

### 1. –î–æ–±–∞–≤–∏—Ç—å –≤ shared/logger.py

```python
# factory_parsers/shared/logger.py
# (—Å–º. –≤—ã—à–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é)
```

### 2. –î–æ–±–∞–≤–∏—Ç—å –≤ shared/metrics.py

```python
# factory_parsers/shared/metrics.py
# (—Å–º. –≤—ã—à–µ Prometheus –º–µ—Ç—Ä–∏–∫–∏)
```

### 3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ –∫–∞–∂–¥—ã–π —Å–µ—Ä–≤–∏—Å

```python
# factory_parsers/web_scraper_service/run_worker.py

from factory_parsers.shared.logger import setup_logging
from factory_parsers.shared.metrics import track_task, track_http_request

logger = setup_logging("web_scraper_service", "scrapy-worker-1")

# –í –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –∑–∞–¥–∞—á–∏:
try:
    start_time = time.time()
    result = process_tender(tender_data)
    duration_ms = (time.time() - start_time) * 1000
    
    logger.info(
        "tender_processed",
        event_type="success",
        tender_id=tender_data['id'],
        duration_ms=int(duration_ms),
        http_status=200
    )
    track_task("web_scraper", "tender_parse", True, duration_ms)
except Exception as e:
    logger.error(
        "tender_processing_failed",
        event_type="error",
        tender_id=tender_data['id'],
        error_code=str(type(e).__name__),
        error_message=str(e)
    )
    track_task("web_scraper", "tender_parse", False, duration_ms)
```

### 4. Docker Compose –¥–ª—è –≤—Å–µ–π —Å—Ç–µ–∫–∞

```yaml
version: '3.9'

services:
  # Elasticsearch + Logstash + Kibana
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.0.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  kibana:
    image: docker.elastic.co/kibana/kibana:8.0.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert-rules.yml:/etc/prometheus/alert-rules.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'

  # Grafana
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"
    depends_on:
      - prometheus

  # Alert Manager
  alertmanager:
    image: prom/alertmanager:latest
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"

volumes:
  elasticsearch_data:
  prometheus_data:
  grafana_data:
```

---

## üîç –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤

### Kibana/Loki queries

```bash
# –ù–∞–π—Ç–∏ –≤—Å–µ –æ—à–∏–±–∫–∏ 429 –ø–æ –ø–ª–æ—â–∞–¥–∫–∞–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å
service="web_scraper_service" AND http_status=429 AND timestamp>=now-1h
| stats count() by platform_id

# –ö–∞–∫–∏–µ –ø—Ä–æ–∫—Å–∏ —á–∞—â–µ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è?
http_status=403 | stats count() by proxy_id | sort -count
| limit 10

# –ö–æ–≥–¥–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –∫–∞–ø—á–∏?
captcha_used=true | stats count() by platform_id, captcha_type

# –ì–¥–µ —Å–∞–º–æ–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏?
| stats avg(duration_ms), max(duration_ms), percentile(duration_ms, 95) by service

# –í—Å–µ retry —Å–æ–±—ã—Ç–∏—è
event_type="retry" | stats count() by service, error_code

# Circuit breaker —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
event_type="circuit_breaker" | table timestamp, platform_id, error_message, metadata.circuit_open_duration_seconds
```

### Prometheus queries

```promql
# TPS (tasks per second) –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
rate(factory_parsers_tasks_total[1m])

# –ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫
(rate(factory_parsers_tasks_total{status="error"}[5m]) / rate(factory_parsers_tasks_total[5m])) * 100

# P95 –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
histogram_quantile(0.95, rate(factory_parsers_file_processing_time_seconds_bucket[5m]))

# 429 –æ—à–∏–±–∫–∏ –ø–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º
rate(factory_parsers_http_errors_total{error_code="RATE_LIMITED"}[5m])

# –ö–∞–ø—á –Ω–∞ 1000 –∑–∞–ø—Ä–æ—Å–æ–≤
(rate(factory_parsers_captchas_solved_total[1m]) / rate(factory_parsers_http_requests_total[1m])) * 1000

# –†–∞–∑–º–µ—Ä –æ—á–µ—Ä–µ–¥–∏
factory_parsers_crawler_queue_size
```

---

## üéØ –ê–¥–º–∏–Ω-–¥–∞—à–±–æ—Ä–¥ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞

**–ß—Ç–æ –≤–∏–¥–∏—Ç –∞–¥–º–∏–Ω –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:**

1. **System Overview**
   - –¢–µ–∫—É—â–∏–π TPS (tasks/sec)
   - Error rate %
   - Active tasks
   - Queue backlog

2. **Alerts**
   - –í—Å–µ —Å—Ä–∞–±–∞—Ç–∏–≤—à–∏–µ –∞–ª–µ—Ä—Ç—ã
   - –ü–æ—á–µ–º—É —Å—Ä–∞–±–∞—Ç–∏–ª–∏ (—Å—Å—ã–ª–∫–∞ –Ω–∞ –ª–æ–≥–∏)
   - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ

3. **Per-Platform Stats**
   - Requests/sec
   - Error rate (–∏ –∏—Ö —Ç–∏–ø—ã)
   - Response time (p50/p95/p99)
   - Captcha rate
   - Last 10 errors (—Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ –ø–æ–ª–Ω—ã–π –ª–æ–≥)

4. **Proxy Health**
   - –°—Ç–∞—Ç—É—Å –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–∫—Å–∏
   - Success rate
   - –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ (403/429)
   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: —Ä–æ—Ç–∏—Ä–æ–≤–∞—Ç—å/–∑–∞–º–µ–Ω–∏—Ç—å

5. **Logs with Filters**
   - –ü–æ —Å–µ—Ä–≤–∏—Å—É, –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ, –æ—à–∏–±–∫–µ
   - Drill-down: –∏–∑ –º–µ—Ç—Ä–∏–∫–∏ –≤ –ª–æ–≥
   - –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: URL, proxy, UA, captcha attempt

---

**–í–µ—Ä—Å–∏—è:** 1.0.0  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-12-16  
**–°—Ç–∞—Ç—É—Å:** Production-ready
